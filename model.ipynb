{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Enhanced Crop Recommendation System\n",
        "## Combining Decision Tree and KNN with Ensemble Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier, StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and prepare data\n",
        "df = pd.read_csv('Crop_recommendation.csv')\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nDataset info:\")\n",
        "print(df.info())\n",
        "print(f\"\\nCrop distribution:\")\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data preprocessing\n",
        "print(\"Missing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Encode categorical data\n",
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['label'])\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(['label', 'label_encoded'], axis=1)\n",
        "y = df['label_encoded']\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
        "print(f\"Testing set size: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Individual Models\n",
        "print(\"Training individual models...\\n\")\n",
        "\n",
        "# KNN Model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "# Decision Tree Model\n",
        "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=5)\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# Random Forest (additional strong model)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensemble Methods\n",
        "print(\"Creating ensemble models...\\n\")\n",
        "\n",
        "# 1. Voting Classifier (Hard Voting)\n",
        "voting_hard = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "        ('dt', DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=5)),\n",
        "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10))\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_hard.fit(X_train, y_train)\n",
        "y_pred_voting_hard = voting_hard.predict(X_test)\n",
        "\n",
        "# 2. Voting Classifier (Soft Voting)\n",
        "voting_soft = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "        ('dt', DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=5)),\n",
        "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10))\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "voting_soft.fit(X_train, y_train)\n",
        "y_pred_voting_soft = voting_soft.predict(X_test)\n",
        "\n",
        "# 3. Stacking Classifier\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "        ('dt', DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=5))\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
        "    cv=5\n",
        ")\n",
        "stacking_model.fit(X_train, y_train)\n",
        "y_pred_stacking = stacking_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "    \n",
        "    print(f\"{model_name} Results:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall: {recall:.4f}\")\n",
        "    print(f\"  F1-score: {f1:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate all models\n",
        "print(\"Model Performance Comparison:\\n\")\n",
        "\n",
        "results = {}\n",
        "results['KNN'] = evaluate_model(y_test, y_pred_knn, \"KNN\")\n",
        "results['Decision Tree'] = evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
        "results['Random Forest'] = evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
        "results['Voting (Hard)'] = evaluate_model(y_test, y_pred_voting_hard, \"Voting Classifier (Hard)\")\n",
        "results['Voting (Soft)'] = evaluate_model(y_test, y_pred_voting_soft, \"Voting Classifier (Soft)\")\n",
        "results['Stacking'] = evaluate_model(y_test, y_pred_stacking, \"Stacking Classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(results.keys()),\n",
        "    'Accuracy': [results[model][0] for model in results.keys()],\n",
        "    'Precision': [results[model][1] for model in results.keys()],\n",
        "    'Recall': [results[model][2] for model in results.keys()],\n",
        "    'F1-Score': [results[model][3] for model in results.keys()]\n",
        "})\n",
        "\n",
        "print(\"\\nModel Comparison Summary:\")\n",
        "print(comparison_df.round(4))\n",
        "\n",
        "# Find best model\n",
        "best_model_idx = comparison_df['Accuracy'].idxmax()\n",
        "best_model = comparison_df.loc[best_model_idx, 'Model']\n",
        "best_accuracy = comparison_df.loc[best_model_idx, 'Accuracy']\n",
        "\n",
        "print(f\"\\nBest performing model: {best_model} with accuracy: {best_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot 1: Model Accuracy Comparison\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.bar(comparison_df['Model'], comparison_df['Accuracy'], color='skyblue')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylim(0.9, 1.0)\n",
        "\n",
        "# Plot 2: All Metrics Comparison\n",
        "plt.subplot(2, 2, 2)\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "x = np.arange(len(comparison_df))\n",
        "width = 0.2\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.bar(x + i*width, comparison_df[metric], width, label=metric)\n",
        "\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Score')\n",
        "plt.title('All Metrics Comparison')\n",
        "plt.xticks(x + width*1.5, comparison_df['Model'], rotation=45)\n",
        "plt.legend()\n",
        "plt.ylim(0.9, 1.0)\n",
        "\n",
        "# Plot 3: Confusion Matrix for Best Model\n",
        "plt.subplot(2, 2, 3)\n",
        "if best_model == 'Voting (Soft)':\n",
        "    best_predictions = y_pred_voting_soft\n",
        "elif best_model == 'Voting (Hard)':\n",
        "    best_predictions = y_pred_voting_hard\n",
        "elif best_model == 'Stacking':\n",
        "    best_predictions = y_pred_stacking\n",
        "else:\n",
        "    best_predictions = y_pred_dt  # fallback\n",
        "\n",
        "cm = confusion_matrix(y_test, best_predictions)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title(f'Confusion Matrix - {best_model}')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-validation for ensemble models\n",
        "print(\"Cross-validation scores (5-fold):\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "models_for_cv = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=5),\n",
        "    'Voting (Soft)': voting_soft,\n",
        "    'Stacking': stacking_model\n",
        "}\n",
        "\n",
        "cv_results = {}\n",
        "for name, model in models_for_cv.items():\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    cv_results[name] = cv_scores\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Mean CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "    print(f\"  Individual scores: {cv_scores.round(4)}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance from the best tree-based model\n",
        "if 'Decision Tree' in best_model or 'Random Forest' in best_model:\n",
        "    if 'Random Forest' in best_model:\n",
        "        feature_importance = rf_model.feature_importances_\n",
        "    else:\n",
        "        feature_importance = dt_model.feature_importances_\n",
        "    \n",
        "    feature_names = X.columns\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': feature_importance\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    \n",
        "    print(\"Feature Importance:\")\n",
        "    print(importance_df)\n",
        "    \n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(importance_df['Feature'], importance_df['Importance'])\n",
        "    plt.title('Feature Importance')\n",
        "    plt.xlabel('Features')\n",
        "    plt.ylabel('Importance')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prediction function for new data\n",
        "def predict_crop(N, P, K, temperature, humidity, ph, rainfall, model_choice='best'):\n",
        "    \"\"\"\n",
        "    Predict crop recommendation based on soil and climate parameters\n",
        "    \n",
        "    Parameters:\n",
        "    - N, P, K: Soil nutrient levels\n",
        "    - temperature: Temperature in Celsius\n",
        "    - humidity: Humidity percentage\n",
        "    - ph: Soil pH level\n",
        "    - rainfall: Rainfall in mm\n",
        "    - model_choice: 'knn', 'dt', 'voting_soft', 'stacking', or 'best'\n",
        "    \"\"\"\n",
        "    \n",
        "    # Prepare input data\n",
        "    input_data = np.array([[N, P, K, temperature, humidity, ph, rainfall]])\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    \n",
        "    # Select model\n",
        "    if model_choice == 'knn':\n",
        "        model = knn_model\n",
        "    elif model_choice == 'dt':\n",
        "        model = dt_model\n",
        "    elif model_choice == 'voting_soft':\n",
        "        model = voting_soft\n",
        "    elif model_choice == 'stacking':\n",
        "        model = stacking_model\n",
        "    else:  # best model\n",
        "        if best_model == 'Voting (Soft)':\n",
        "            model = voting_soft\n",
        "        elif best_model == 'Stacking':\n",
        "            model = stacking_model\n",
        "        else:\n",
        "            model = dt_model\n",
        "    \n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_scaled)[0]\n",
        "    crop_name = le.inverse_transform([prediction])[0]\n",
        "    \n",
        "    # Get prediction probabilities if available\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        probabilities = model.predict_proba(input_scaled)[0]\n",
        "        top_3_indices = np.argsort(probabilities)[-3:][::-1]\n",
        "        top_3_crops = le.inverse_transform(top_3_indices)\n",
        "        top_3_probs = probabilities[top_3_indices]\n",
        "        \n",
        "        print(f\"Recommended crop: {crop_name}\")\n",
        "        print(f\"\\nTop 3 recommendations:\")\n",
        "        for i, (crop, prob) in enumerate(zip(top_3_crops, top_3_probs)):\n",
        "            print(f\"{i+1}. {crop}: {prob:.3f}\")\n",
        "    else:\n",
        "        print(f\"Recommended crop: {crop_name}\")\n",
        "    \n",
        "    return crop_name\n",
        "\n",
        "# Example prediction\n",
        "print(\"Example Crop Prediction:\")\n",
        "print(\"Input: N=90, P=42, K=43, Temperature=20.9, Humidity=82, pH=6.5, Rainfall=202\")\n",
        "predicted_crop = predict_crop(90, 42, 43, 20.9, 82, 6.5, 202, 'best')\n",
        "print(f\"\\nUsing {best_model} model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This enhanced crop recommendation system combines Decision Tree and KNN models using several ensemble techniques:\n",
        "\n",
        "1. **Voting Classifier (Hard)**: Takes majority vote from all models\n",
        "2. **Voting Classifier (Soft)**: Averages prediction probabilities\n",
        "3. **Stacking Classifier**: Uses a meta-learner (Logistic Regression) to combine predictions\n",
        "\n",
        "The ensemble methods typically provide better performance than individual models by:\n",
        "- Reducing overfitting\n",
        "- Improving generalization\n",
        "- Combining strengths of different algorithms\n",
        "- Providing more robust predictions\n",
        "\n",
        "Choose the best performing model based on your specific requirements for accuracy, interpretability, and computational efficiency."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}